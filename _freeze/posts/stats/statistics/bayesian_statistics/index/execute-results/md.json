{
  "hash": "81bcb05e75974517efaeb5435ae3c6fa",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Bayesian Statistics model comparison\"\nauthor: Federica Gazzelloni\ndate: '2023-03-22'\nformat: hugo\nslug: bayesian-statistics\ncategories:\n  - rstats\n  - modeling\ntags:\n  - rstats\n  - modeling\nsummary: \"Looking at bayesian model comparisons\"\n---\n\n\n\n\n# Overview\n\nIn this post I'll go through some differences between *Bayesian statistical packages* in R.\n\nBayesian statistics involves probabilities. This means that the probability of an event to occur is considered in the modeling procedure, and is mainly used in for making **inferences**, and can be used for an analysis of the speculation of the root cause of a phenomenon under the term of **causal inference**.\n\nIn more details, when Bayesian statistics is performed, the response variable is tested against (causal) predictors with the application of suited **prior** distributions, and the use of the **likelihood function**, to finally produce a **posterior** distribution which should be as much as possible close to the real future outcome of the response variable distribution.\n\nThe **prior distribution** is the starting point; it is the probability distribution on which the future outcome is linked to, such as the probability to have a *Girl* given the probability to have had a *Boy*.\n\n$$P( \\text{ Girl } | \\text{ Boy })$$\n\nThe probability to have had a *Boy* is the **prior**, while the conditional probability to have a *Girl* is the posterior.\n\nBriefly, here is a comparison between different R packages that use *Bayesian inference* for the calculation of the model probability distribution of the *posterior*.\n\nThe **Stan** model engine, for model replication and prediction is used in conjunction with the **Montecarlo simulation** technique for the best model solution. The *Stan* model engine is applied in the following packages:\n\n-   brms\n-   rstanarm\n-   rethinking\n-   MCMCglmm\n\nAll of these packages adapt and adjust different model options for a modeling procedure which is the result of the best combination of efficiency to increase productivity and effectiveness, to identify and remove unnecessary steps, automate repetitive tasks, and utilize the most suitable software tools.\n\nThis is the original source code that I have updated: <https://www.jstatsoft.org/article/view/v080i01>\n\n> A wide range of distributions and link functions are supported, allowing users to fit - among others - linear, robust linear, binomial, Poisson, survival, ordinal, zero-inflated, hurdle, and even non-linear models all in a multilevel context. (The Brms package)\n\nLoading required packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"brms\") \nlibrary(\"rstanarm\")\nlibrary(\"rethinking\") \nlibrary(\"MCMCglmm\")  \n```\n:::\n\n\nHelper function to better compute the effective sample size\n\n\n::: {.cell}\n\n```{.r .cell-code}\neff_size <- function(x) {\n  if (is(x, \"brmsfit\")) {\n    samples <- as.data.frame(x$fit)\n  } else if (is(x, \"stanreg\")) {\n    samples <- as.data.frame(x$stanfit)\n  } else if (is(x, \"ulam\")) {\n    samples <- as.data.frame(x@stanfit)\n  } else if (is(x, \"stanfit\")) {\n    samples <- as.data.frame(x)\n  } else if (is(x, \"MCMCglmm\")) {\n    samples <- cbind(x$Sol, x$VCV)\n  } else {\n    stop(\"invalid input\")\n  }\n  # call an internal function of rstan\n  floor(apply(samples, MARGIN = 2, FUN = rstan:::ess_rfun))\n}\n```\n:::\n\n\n### Compare efficiency between packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# only used for Stan packages\niter <- 6000  \nwarmup <- 1000\nchains <- 1\nadapt_delta <- 0.8\n\n# only used for MCMCglmm\nnitt <- 35000  \nburnin <- 10000\nthin <- 5\n# leads to 5000 posterior samples\n```\n:::\n\n\n## Dyestuff\n\n### brms\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior_dye_brms <- c(set_prior(\"normal(0, 2000)\", class = \"Intercept\"),\n                    set_prior(\"cauchy(0, 50)\", class = \"sd\"),\n                    set_prior(\"cauchy(0, 50)\", class = \"sigma\"))\n\ndye_brms <- brm(Yield ~ 1 + (1 | Batch), \n                data = lme4::Dyestuff, \n                prior = prior_dye_brms, \n                chains = 0)\n\ntime_dye_brms <- system.time(capture.output(\n  dye_brms <- update(dye_brms, \n                     iter = iter, \n                     warmup = warmup, \n                     chains = chains,\n                     control = list(adapt_delta = adapt_delta))\n))\n# summary(dye_brms)\neff_dye_brms <- min(eff_size(dye_brms)) / time_dye_brms[[1]]\n```\n:::\n\n\n### rstanarm\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntime_dye_rstanarm <- system.time(capture.output(\n  dye_rstanarm <- stan_glmer(Yield ~ 1 + (1 | Batch), data = lme4::Dyestuff,\n                             prior_intercept = normal(0, 2000),\n                             iter = iter, warmup = warmup, chains = chains,\n                             adapt_delta = adapt_delta)\n))\n# summary(dye_rstanarm)\neff_dye_rstanarm <- min(eff_size(dye_rstanarm)) / time_dye_rstanarm[[1]]\n```\n:::\n\n\n### rethinking\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <-  lme4::Dyestuff\n\ndat <- list(\n  Yield = d$Yield,\n  Batch = d$Batch\n)\n\ndye_flist <- alist(\n  Yield ~ dnorm(eta, sigma),\n  eta <- a + a_Batch[Batch],\n  a ~ dnorm(0,2000),\n  a_Batch[Batch] ~ dnorm(0, sd_Batch),\n  sigma ~ dcauchy(0, 50),\n  sd_Batch ~ dcauchy(0, 50))\n\ndye_rethinking <- ulam(dye_flist, \n                       data = dat, \n                       chains=1,\n                       cores = 4,\n                       sample = TRUE)\n\ntime_dye_rethinking <- system.time(capture.output(\n  dye_rethinking <- update(dye_rethinking,\n       iter = iter, \n       warmup = warmup, \n       chains = chains,\n       control = list(adapt_delta = adapt_delta))\n))\n\n\n# summary(dye_rethinking)\neff_dye_rethinking <- min(eff_size(dye_rethinking)) / time_dye_rethinking[[1]]\n```\n:::\n\n\n### MCMCglmm\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntime_dye_MCMCglmm <- system.time(capture.output(\n  dye_MCMCglmm <- MCMCglmm(Yield ~ 1, \n                           random = ~ Batch, data = lme4::Dyestuff, \n                           thin = thin, nitt = nitt, burnin = burnin)\n))\n# summary(dye_MCMCglmm)\neff_dye_MCMCglmm <- min(eff_size(dye_MCMCglmm)) / time_dye_MCMCglmm[[1]]\n```\n:::\n\n\n### Efficiency\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(c(brms = eff_dye_brms, \n        rstanarm = eff_dye_rstanarm, \n        rethinking = eff_dye_rethinking, \n        MCMCglmm = eff_dye_MCMCglmm))\n```\n:::\n\n\n\n\n| brms      | rstanarm  | rethinking | MCMCglmm |\n|-----------|-----------|------------|----------|\n| 559.55398 | 202.97177 | 3660.71429 | 34.11514 |\n\n\n(to be continued...)\n\n\n\n\n```\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}